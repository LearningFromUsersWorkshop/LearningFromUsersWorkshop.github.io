([2018 workshop page can be found here](workshop2018.md))

([2019 workshop page can be found here](workshop2019.md))

## 2020 Workshop Summary

**Date and Location:** TBD, held virtually

The Machine Learning from User Interactions (MLUI) workshop seeks to bring together researchers to share their knowledge and build collaborations at the intersection of the Machine Learning and Visualization fields, with a focus on learning from user interaction.  Rather than focusing on what visualization can do to support machine learning (as in current Explainable AI research), this workshop seeks contributions on **how machine learning can support visualization**.  Such support incorporates human-centric sensemaking processes, user-driven analytical systems, and gaining insight from data.  Our intention in this workshop is to generate open discussion about how we currently learn from user interaction, how to build intelligent visualization systems, and how to proceed with future research in this area. We hope to foster discussion regarding systems, interaction models, and interaction techniques. Further, we hope to extend last year's collaborative creation of a research agenda that explores the future of machine learning with user interaction.

## WORKSHOP TOPICS

The topic of the workshop will focus on issues and opportunities related to the use of machine learning to learn from user interaction in the course of data visualization and analysis. Specifically, we will focus on research questions including:

- How are machine learning algorithms currently learning from user interaction, and what other possibilities exist?
- What kinds of interactions can provide feedback to machine learning algorithms?
- What can machine learning algorithms learn from interactions?
- Which machine learning algorithms are most applicable in this domain?
- How can machine learning algorithms be designed to enable user interaction and feedback?
- How can visualizations and interactions be designed to exploit machine learning algorithms?
- How can visualization system architectures be designed to support machine learning?
- How should we manage conflicts between the user's intent and the data or machine learning algorithm capabilities?
- How can we evaluate systems that incorporate both machine learning algorithms and user interaction together?
- How can machine learning and user interaction together make both computation and user cognition more efficient?
- How can we support the sensemaking process by learning from user interaction?


## KEYNOTES

**Keynote 1:  Machine Learning meets Visualization**

**Abstract:**  Based on our experience conducting projects at the intersection of machine learning (ML) and interactive visualization (Vis), my talk will reflect on and discuss the current relation between these two areas.  For that purpose, the talkâ€™s structure will follow two main streams.  First, I will talk about *Vis for ML*, that is, the idea that visualization can help machine learning researchers and practitioners gain interesting insights into their models. In the second part, I will then turn the relationship around and discuss how *ML for Vis* can guide visualization designers and analysts towards interesting visual patterns in the data. The talk will conclude with research challenges that lie ahead of us and that will pave the way for future interfaces between humans and data.

**Biography:**  Michael Sedlmair is a junior professor at the University of Stuttgart, where he works at the intersection of human-computer interaction, visualization, and data analysis. Previously, Michael has worked at Jacobs University Bremen, University of Vienna, University of British Columbia, University of Munich (where he got his PhD), and the BMW Group Research and Technology. He also holds visiting positions at the Vienna University of Technology, and the Shandong University.  His interests focus on information visualization, interactive machine learning, virtual and augmented reality, as well as the research and evaluation methodologies underlying them.


**Keynote 2:  Using Models and Predictions to Help Humans and Computers Click**

**Abstract:**  There is a fast-growing interest in analyzing user interaction to create adaptive systems that can assist or collaborate on data analysis. However, the first step for an intelligent response in visualization is to Understand the User. The goal is to enable computers to infer user attributes and strategies by observing their interactions with a system. In this talk, Dr. Ottley summarizes user modeling for data visualization and gives a snapshot of where we are as a community and what is possible in the near and distant future. She presents techniques for modeling and predicting user behavior, focusing on inferring attention, personality, biases, and knowledge by analyzing log data. Finally, Dr. Ottley highlights the major roadblocks and future directions for provenance-related research. 

**Biography:**  Dr. Alvitta Ottley is an Assistant Professor in the Department of Computer Science & Engineering at Washington University in St. Louis, Missouri, USA. She also holds a courtesy appointment in the Department of Psychological and Brain Sciences. Her research uses interdisciplinary approaches to solve problems such as how best to display information for effective decision-making and how to design human-in-the-loop visual analytics interfaces that are more attuned to the way people think. Dr. Ottley was the recipient of an NSF CRII Award in 2018 for using visualization to support medical decision-making. Her work has appeared in leading conferences and journals such as CHI, VIS, and TVCG.


## SUBMISSIONS

We have two submission tracks, supporting both papers and late-breaking work.

### Papers

We invite research and position papers between 5 and 10 pages in length (NOT including references).  All submissions must be formatted according to the [VGTC conference style template](http://junctionpublishing.org/vgtc/Tasks/camera.html) (i.e., NOT the journal style template that full papers use).  All papers accepted for presentation at the workshop will be published and linked from the workshop website.  All papers should contain full author names and affiliations.  These papers are considered archival; reuse of the content in a follow-up publication is only permitted in a proper journal, and any extended version must extend the original paper by at least 30%.  If applicable, a link to a short video (up to 5 min. in length) may also be submitted. The papers will be juried by the organizers and selected external reviewers and will be chosen according to relevance, quality, and likelihood that they will stimulate and contribute to the discussion. At least one author of each accepted paper needs to register  for the conference (even if only for the workshop).  Papers should be submitted to the "[VIS 2020 MLUI 2020](https://new.precisionconference.com/submissions)" track in PCS under the VGTC Society.
  
#### Important Dates

Submission deadline:  July 24, 2020 

Author notification:  August 12, 2020

Camera-ready deadline:  August 21, 2020

Speaker Schedule Available:  October 1, 2020

Workshop:  October 25 or 26, 2020

### Late-Breaking Work

We anticipate that some participants would prefer to discuss either (1) limited aspects of their larger work that fit our call, or (2) late-breaking work.  This replaces the posters track that we previously offered at MLUI.  Submissions for this track will only require a ~250 word abstract, and selected talks will receive 5 minutes to present their current work.  Further submission details will follow.
  
#### Important Dates

Submission deadline:  October 1, 2020

Author notification:  October 8, 2020

Workshop:  October 25 or 26, 2020

## ORGANIZERS

John Wenskovitch, Pacific Northwest National Lab and Virginia Tech (jw87@vt.edu)

Michelle Dowling, Grand Valley State University (dowlingm@vt.edu)

Eli T. Brown, DePaul University

Kris Cook, Pacific Northwest National Lab

Ab Mosca, Tufts University

Conny Walchshofer, Johannes Kepler University Linz

Marc Streit, Johannes Kepler University Linz

Kai Xu, Middlesex University

### Steering Committee

Chris North, Virginia Tech

Remco Chang, Tufts University

Alex Endert, Georgia Tech

David Rogers, Los Alamos National Lab
